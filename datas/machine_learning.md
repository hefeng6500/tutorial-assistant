机器学习

条目
讨论
汉漢

大陆简体
阅读
编辑
查看历史

工具
外观 隐藏
文本

小

标准

大
宽度

标准

宽
颜色 （测试版）

自动

浅色

深色
维基百科，自由的百科全书

本条目存在以下问题，请协助改善本条目或在讨论页针对议题发表看法。
此条目可参照英语维基百科相应条目来扩充。
若您熟悉来源语言和主题，请协助参考外语维基百科扩充条目。请勿直接提交机械翻译，也不要翻译不可靠、低品质内容。依版权协议，译文需在编辑摘要注明来源，或于讨论页顶部标记{{Translated page}}标签。
此条目需要补充更多来源。 (2025年4月12日)
请协助补充多方面可靠来源以改善这篇条目，无法查证的内容可能会因为异议提出而被移除。
致使用者：请搜索一下条目的标题（来源搜索："机器学习" — 网页、新闻、书籍、学术、图像），以检查网络上是否存在该主题的更多可靠来源（判定指引）。
此条目已列出参考文献，但因为没有文内引注而使来源仍然不明。 (2025年6月7日)
请加上合适的文内引注来改善这篇条目。
提示：此条目的主题不是机械学习或机器人学习。
机器学习与数据挖掘

范式
问题
监督学习
(分类 · 回归)
聚类分析
降维
结构预测
异常检测
人工神经网络
强化学习
与人类学习
模型诊断
数学基础
大会与出版物
相关条目
查论编
人工智能系列内容

主要目标
实现方式
人工智能哲学
历史
人工智能的应用
主题与列表
查论编
机器学习（英语：machine learning，简称ML）是人工智能的一个分支。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法（要防止错误累积）。很多推论问题属于非程序化決策，所以部分的机器学习研究是开发容易处理的近似算法。

机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、游戏和机器人等领域。机器学习在近30多年已发展为一门多领域科际集成，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论、信息论等多门学科。

参见：机器学习概述
定义
机器学习有下面几种定义：

机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。
机器学习是对能通过经验自动改进的计算机算法的研究。
机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。
另外，计算机科学家汤姆·米切尔在其著作的Machine Learning一书中定义的机器学习为[1]：

A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

——Tom Mitchell，Machine Learning
历史
参见：人工智能史
与其他领域的关系
作为一项科学事业，机器学习起源于人类对人工智能（Artificial Intelligence，简称AI）的探索。在AI作为学术领域早期阶段，一些研究者希望能让机器从数据中学习。他们尝试通过多种符号方法（symbolic methods）来解决这个问题，同时也采用了当时称为“神经网络”（neural networks）的方法。这些神经网络模型主要包括感知机（perceptrons）以及其他一些模型，后来发现这些模型实际上是统计学中广义线性模型（generalized linear models）的重新发明。此外，当时研究者还广泛使用概率推理（probabilistic reasoning）方法，尤其是在自动化医学诊断领域。

然而，随着学术界对逻辑和基于知识的（knowledge-based）方法日益强调，人工智能（AI）和机器学习之间逐渐产生了分歧。概率系统（probabilistic systems）也面临着数据获取和数据表示方面的理论与实际问题。到1980年左右，专家系统（expert systems）开始在人工智能领域占据主导地位，统计学方法逐渐被边缘化。在AI领域内部，符号学习（symbolic learning）或知识学习（knowledge-based learning）的研究依然继续，并催生了归纳逻辑编程（inductive logic programming，简称ILP）。而更为侧重统计方法的研究，则逐渐被归类到模式识别（pattern recognition）和信息检索（information retrieval）等领域，不再属于AI的核心研究方向。同时，神经网络（neural networks）的研究也在AI和计算机科学（computer science）领域被逐渐放弃。这条研究路径后来在AI和计算机科学之外继续发展，形成了以“联结主义”（connectionism）为代表的学派，由其他领域的研究者推动，如约翰·霍普菲尔德（John Hopfield）、大卫·鲁梅尔哈特（David Rumelhart）和杰弗里·辛顿（Geoffrey Hinton）等人。他们的研究在1980年代中期获取了重要突破，其中以反向传播算法（backpropagation）的重新发现最为显著。

机器学习（Machine Learning，简称ML）在1990年代被重新集成并确立为独立的研究领域，并开始蓬勃发展。这一领域的目标也从最初追求实现人工智能（Artificial Intelligence，简称AI），转变为解决实际中能够被有效解决的问题。研究重心逐渐远离了继承自AI的符号方法（symbolic approaches），转向了从统计学（statistics）、模糊逻辑（fuzzy logic）以及概率理论（probability theory）中借鉴的方法和模型。

理论
主条目：计算学习理论和统计学习理论
学习器（learner）的核心目标之一是从经验中进行泛化（generalize）。在这一背景下，泛化指的是学习机器在经历了训练数据集（learning data set）之后，能够在新出现的、未曾见过的样本或任务上准确表现的能力。这些训练样本通常来自某个未知的概率分布（probability distribution，这个概率分布被认为能代表真实场景中事件的分布空间），学习器需要基于这些数据构建出一个一般化的模型，从而能够对新的情景或样本做出足够准确的预测。

对机器学习算法及其性能进行的计算分析，是理论计算机科学（theoretical computer science）的一个分支，称为计算学习理论（computational learning theory），通常通过概率近似正确学习模型（probably approximately correct learning，简称PAC Learning）实现。由于训练集（training sets）是有限的，而未来又充满不确定性，因此学习理论通常并不能绝对保证算法的表现；取而代之的是，通常会给出算法性能的概率性界限（probabilistic bounds）。偏差-方差分解（bias–variance decomposition）是一种用于量化泛化误差（generalization error）的方法。

为了获得最佳的泛化（generalization）性能，假设（hypothesis，也即模型）的复杂度应与数据背后的真实函数（function）的复杂度相匹配。如果假设的复杂度低于真实函数的复杂度，那么模型就会出现欠拟合（underfitting）的现象；在这种情况下，适当增加模型的复杂度可以降低训练误差（training error）。然而，如果假设的复杂度过高，模型又会面临过拟合（overfitting）问题，从而导致泛化能力下降。

除了研究性能界限（performance bounds）之外，学习理论的研究人员也关注学习的时间复杂度（time complexity）和可行性（feasibility）。在计算学习理论（computational learning theory）中，如果某个计算可以在多项式时间（polynomial time）内完成，那么就被视为是可行的（feasible）。关于时间复杂度，有两种类型的结果：

正面结果（Positive results） 表明某一类函数可以在多项式时间内被学习；
负面结果（Negative results） 表明某些函数类别无法在多项式时间内被学习。
分类


在监督学习（supervised learning）中，训练数据带有预期的输出标签，模型的任务是学习输入与输出之间的映射关系；而在无监督学习（unsupervised learning）中，数据是未标注的，模型需要在没有明确答案的情况下，自主发现其中的模式或结构。
机器学习方法传统上被划分为以下几类，对应不同的学习范式（learning paradigms），具体取决于学习系统可获得的“信号”或“反馈”的类型：

监督学习：从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注的。常见的监督学习算法包括回归分析和统计分类。监督学习和非监督学习的差别就是训练集目标是否有人为标注。他们都有训练集 且都有输入和输出
无监督学习：与监督学习相比，训练集没有人为标注的结果。常见的无监督学习算法有生成对抗网络（GAN）、聚类。
半监督学习：介于监督学习与无监督学习之间。
强化学习：机器为了达成目标，随着环境的变动，而逐步调整其行为，并评估每一个行动之后所到的回馈是正向的或负向的。[2]
模型与方法
参见：机器学习概述 § 机器学习方法
机器学习模型是一种数学模型，在经过某个数据集的“训练”之后，可以用于对新数据进行预测或分类。在训练过程中，学习算法会通过迭代不断调整模型的内部参数，以尽可能减少预测误差。广义上，“模型”一词可以指代不同层级的内容：既可以是某一类模型及其对应的学习算法，也可以是所有内部参数都已经调整完毕、训练完成的具体模型。

在机器学习系统中，已经研究和应用了多种类型的模型。为特定任务选择最合适的模型的过程被称为模型选择（model selection）**。

具体的机器学习模型有：

构造间隔理论分布：聚类分析和模式识别
人工神经网络
决策树
感知器
支持向量机
集成学习AdaBoost
降维与度量学习
聚类
贝叶斯分类器
构造条件概率：回归分析和统计分类
高斯过程回归
线性判别分析
最近邻居法
径向基函数核
通过再生模型构造概率密度函数：
最大期望算法
概率图模型：包括贝叶斯网络和Markov随机场
Generative Topographic Mapping
近似推断技术：
马尔可夫链
蒙特卡罗方法
变分法
最优化：大多数以上方法，直接或者间接使用最优化算法。
量子机器学习
人工神经网络
主条目：人工神经网络
参见：深度学习

人工神经网络（Artificial Neural Network，简称ANN）是由多个节点（node）相互连接构成的结构，类似于大脑中由神经元（neurons）组成的庞大网络。在这个网络中，每一个圆形节点代表一个人工神经元（artificial neuron），而箭头表示从一个神经元的输出传递到另一个神经元输入的连接。
人工神经网络（Artificial Neural Networks，简称ANNs），又称联结主义系统（connectionist systems），是一类受动物大脑中生物神经网络启发而构建的计算系统。这类系统通过学习样本来完成任务，而通常不依赖于任何针对特定任务的预设规则。换句话说，它们是通过观察大量示例，逐步“学会”如何解决问题的。

人工神经网络（ANN）是一种由多个相互连接的单元或节点构成的模型，这些节点被称为“人工神经元”，其灵感来源于生物大脑中的神经元。在人工神经网络中，每个连接类似于生物大脑中的突触，可以在人工神经元之间传递信息，也就是“信号”。

一个接收到信号的人工神经元可以对其进行处理，并将处理后的信号传递给与其连接的其他人工神经元。在常见的ANN实现中，神经元之间连接所传递的信号是一个实数，而每个人工神经元的输出是其所有输入的加权和经过某种非线性函数变换后的结果。

神经元之间的连接称为“边”（edges）。人工神经元和连接边通常都带有一个权重，这个权重会随着学习过程的进行而调整。权重决定了信号传递的强度，权重越大，信号越强。有些人工神经元还设有阈值：只有当接收到的总信号超过该阈值时，才会传递输出信号。

通常，人工神经元会被组织成不同的层（layers）。不同的层可能对输入执行不同类型的变换。信号从第一层（输入层）开始，一直传递到最后一层（输出层），过程中可能会多次经过中间的隐藏层。

人工神经网络（ANN）最初的目标是模拟人脑的工作方式来解决问题。然而，随着时间的推移，研究重点逐渐转向如何高效地完成特定任务，这也导致了神经网络的发展逐渐偏离了生物学上的真实神经结构。

尽管如此，人工神经网络已经在众多领域得到了广泛应用，包括：

计算机视觉（computer vision）
语音识别（speech recognition）
机器翻译（machine translation）
社交网络内容过滤（social network filtering）
棋类与电子游戏（playing board and video games）
医学诊断（medical diagnosis）
这些成功应用证明了神经网络在解决复杂、非线性问题方面的强大能力。

深度学习（Deep Learning）是指在人工神经网络中引入多个隐藏层（hidden layers）的一种方法。这种方法试图模拟人脑将光和声音转化为视觉和听觉的处理方式。深度学习在多个领域获取了显著成果，其中计算机视觉（computer vision）和语音识别（speech recognition）是其最成功的应用之一。

决策树
主条目：决策树学习

这是一棵用于展示泰坦尼克号（Titanic）乘客生存概率的决策树（Decision Tree）。它通过一系列的“如果...那么...”的决策规则，对数据进行分裂，最终预测结果。在泰坦尼克号的例子中，决策树可能会根据以下特征进行分裂，例如：乘客的性别（gender）、年龄（Age）、是否有家庭成员同行（SibSp）等。
决策树学习（Decision Tree Learning）是一种使用决策树作为预测模型的方法，通过对一个对象的观察（表示在树的分支上），推导出该对象的目标值（表示在叶子节点上）。它是统计学、数据挖掘和机器学习中常用的一种预测建模方法。

当目标变量是离散值（例如分类标签）时，所构建的树被称为分类树（Classification Tree）。在这类树结构中，叶子节点代表类别标签，分支则代表导致这些标签的特征组合。
当目标变量是连续值（通常是实数）时，该树称为回归树（Regression Tree）。
在决策分析（Decision Analysis）中，决策树可以被用来直观、明确地表示决策过程及其可能结果。而在数据挖掘（Data Mining）中，决策树不仅可以用来描述数据本身，其生成的分类树还可以作为后续决策的依据。

总结来说，决策树是一种结构清晰、解释性强的模型，适合处理既有分类又有回归问题。

随机森林回归
随机森林回归（Random forest regression, RFR）属于基于决策树的模型范畴。RFR 是一种集成学习方法（ensemble learning method），它通过构建多个决策树并对其预测结果进行平均，从而提高预测的准确性并有效避免过拟合。

在构建决策树的过程中，RFR 采用自助采样法（bootstrapped sampling），也就是说，每棵决策树都是在训练集中随机抽取的一部分数据上进行训练的。这种训练方式的“随机性”有助于减少模型的偏差，使预测结果更加准确。

RFR 会生成相互独立的多个决策树，它既可以用于单一输出变量的回归问题，也可以用于多回归任务（multiple regressor task）。这种灵活性使得 RFR 能够被广泛应用于各种实际场景中。

支持向量机
主条目：支持向量机
支持向量机（SVM），也称为支持向量网络（Support-Vector Networks），是一组用于分类（classification）和回归（regression）的监督学习方法。在给定一组训练样本的前提下，其中每个样本都被标注为属于两个类别之一，SVM 的训练算法会构建一个模型，用来预测新的样本属于哪个类别。SVM 是一种非概率性的二分类线性分类器，虽然也有像 Platt scaling 这样的扩展方法，可以使其应用于概率分类任务。

除了进行线性分类，SVM 还可以借助所谓的核技巧（kernel trick），高效地实现非线性分类。这种方法通过隐式地将输入映射到高维特征空间，使得在原本线性不可分的问题中，也能找到一个可分的超平面，从而实现更复杂的分类效果。

回归分析
主条目：回归分析
回归分析（Regression analysis）是一个涵盖广泛的统计方法集合，主要用于估计输入变量与其相关特征之间的关系。其中最常见的形式是线性回归（Linear Regression），通过一条直线来最优地拟合给定数据，这条线通常依据某种数学准则（如最小二乘法，Ordinary Least Squares）确定。

为了减轻过拟合（overfitting）和偏差（bias）的问题，线性回归往往会结合正则化方法（regularization methods）进行扩展，例如岭回归（Ridge Regression）。

在面对非线性问题时，常用的替代模型包括：

多项式回归（Polynomial Regression）：如 Microsoft Excel 中用于趋势线拟合的工具；
逻辑回归（Logistic Regression）：广泛用于统计分类任务；
核回归（Kernel Regression）：利用核技巧（kernel trick）将输入变量隐式映射到更高维空间，从而引入非线性。
这些模型能够更灵活地拟合和预测现实中复杂的数据关系。

多元线性回归（Multivariate Linear Regression）是在传统线性回归的基础上扩展而来的，用于同时处理多个因变量（输出变量）的情况。这种方法通过拟合一个多维线性模型，来估计一组输入变量与多个输出变量之间的关系。

多元线性回归特别适用于以下场景：

输出变量之间存在相互依赖关系；
多个输出共享某种潜在的模式或结构。
例如：

同时预测多个经济指标；
重建图像数据（图像本身是多维结构）。
这种方法在处理复杂、关联性强的多输出问题时，能提供更全面和准确的建模能力。

贝叶斯网络
主条目：贝叶斯网络

这是一个简单的贝叶斯网络示例：下雨（Rain）会影响洒水器（Sprinkler）是否启动；而下雨和洒水器的状态共同决定草地是否湿（Grass Wet）
贝叶斯网络（Bayesian Network），又称信念网络（Belief Network）或有向无环图模型（Directed Acyclic Graphical Model），是一种概率图模型（probabilistic graphical model），它通过一个有向无环图（Directed Acyclic Graph,DAG）来表示一组随机变量之间的条件独立性关系。

例如，一张贝叶斯网络可以用于表示疾病与症状之间的概率关系。当给定一些症状时，可以利用该网络计算出不同疾病出现的概率，从而辅助判断可能的病因。

贝叶斯网络配有高效的推理与学习算法，能够处理复杂的概率推断任务。

进一步扩展：

如果贝叶斯网络用于表示变量序列（如语音信号、蛋白质序列等），这样的模型称为动态贝叶斯网络（Dynamic Bayesian Networks）。
能够在不确定性下表示并解决决策问题的贝叶斯网络模型，称为影响图（Influence Diagrams）。
这些图模型在医学诊断、语音识别、机器人决策等领域都有重要应用。

高斯过程
主条目：高斯过程
高斯过程（Gaussian Processes）是一种随机过程（stochastic process），其特点是：在该过程中，任意有限数量的随机变量都服从一个多元正态分布（multivariate normal distribution）。高斯过程依赖于一个预定义的协方差函数（covariance function）或称核函数（kernel），用于建模不同点之间的关系，这种关系取决于它们在空间中的位置。

在给定一组已观测的数据点（即输入-输出样本）后，我们可以通过这些已知点之间的协方差，以及它们与某个新的、未观测点之间的协方差，直接计算该新点的输出值的概率分布，这是高斯过程的核心能力之一。

高斯过程在贝叶斯优化（Bayesian Optimization）中非常受欢迎，常被用作替代模型（surrogate model），特别适合用于超参数优化（hyperparameter optimization）等任务。

软件
包含各种机器学习算法的软件套装包括：

自由开源软件
参见：Machine_learning#Software
Caffe
Deeplearning4j
DeepSpeed
ELKI
JAX
Infer.NET
Keras
Kubeflow
LightGBM
Mahout
Mallet
Microsoft Cognitive Toolkit
ML.NET
mlpack
MXNet
OpenNN
Orange
pandas (software)
ROOT (TMVA with ROOT)
scikit-learn
Shogun
Spark MLlib
SystemML
TensorFlow
Torch / PyTorch
Weka / MOA
XGBoost
Yooreeka
Python软件库及框架
参见：Python § 机器学习
参考文献
引用
 Tom M. Mitchell. Machine Learning. McGraw-Hill. 1997年3月: 第2页. ISBN 0070428077 （英语）.
 林东清. 资讯管理：e化企业的核心竞争能力 七版. 台北市: 智胜文化. 2018年8月: 第118页. ISBN 9789864570478 （中文）.
来源
书籍
Bishop, C. M. (1995). 《模式识别神经网络》，牛津大学出版社. ISBN 0-19-853864-2.
Bishop, C. M. (2006). 《模式识别与机器学习》，Springer. ISBN 978-0-387-31073-2.
Richard O. Duda, Peter E. Hart, David G. Stork (2001). 《模式分类》（第2版）, New York: Wiley. ISBN 0-471-05669-3.
MacKay, D. J. C. (2003). 《信息理论、推理和学习算法》 （页面存档备份，存于互联网档案馆），剑桥大学出版社. ISBN 0-521-64298-1
Mitchel.l, T. (1997). 《机器学习》, McGraw Hill. ISBN 0-07-042807-7
Sholom Weiss, Casimir Kulikowski (1991). Computer Systems That Learn, Morgan Kaufmann. ISBN 1-55860-065-5.
参见
	计算机科学主题
	信息技术主题
	统计学主题
人工智能
生成式人工智能
深度学习
迁移学习
微调 (深度学习)
强化学习
贝叶斯学习
随机森林
决策树
计算学习理论
提示工程
计算智能
数据挖掘
模式识别
自主控制机器人
归纳逻辑编程
神经网络
最近邻居法
机器学习控制
量子机器学习
查论编
机器学习同数据挖掘主题
查论编
可微分计算
查论编
主要的数学领域
查论编
计算机科学的主要领域